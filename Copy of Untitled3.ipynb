{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"V888fj2eXdEt","colab_type":"code","outputId":"98467591-f679-4d9d-caf8-02164f9530b1","executionInfo":{"status":"error","timestamp":1542180090709,"user_tz":-300,"elapsed":3340,"user":{"displayName":"asif aziz","photoUrl":"https://lh4.googleusercontent.com/-bhMjrwpUA3g/AAAAAAAAAAI/AAAAAAAAAVc/lFmV9OMwqzo/s64/photo.jpg","userId":"14665035055551521181"}},"colab":{"base_uri":"https://localhost:8080/","height":4510}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon Nov 12 15:17:45 2018\n","\n","@author: Asif\n","\"\"\"\n","\n","# 3. Import libraries and modules\n","import numpy as np\n","np.random.seed(123)  # for reproducibility\n","import scipy.io\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Convolution2D, MaxPooling2D\n","from keras.utils import np_utils\n","import numpy as np\n","# Dataset Loading\n","\n","a = scipy.io.loadmat('Dataset_for_CNN2')\n","\n","X_train = a['X_train']\n","X_test = a['X_test']\n","y_train = a['y_train'].astype(int)\n","y_test = a['y_test']\n","\n","\n","\n","X_train = X_train.reshape(X_train.shape[0],128, 128,1)\n","X_test = X_test.reshape(X_test.shape[0],128, 128,1)\n","X_train\n","# Preprocess Input Data\n","X_train = X_train.astype('float64')\n","X_test = X_test.astype('float64')\n","X_train /= 255\n","X_test /= 255\n","\n","Y_train = np_utils.to_categorical(y_train, 2).astype(int)\n","Y_test = np_utils.to_categorical(y_test, 2).astype(int)\n","\n","\n"," #Preprocess Class Labels\n","#converting to one hot notation\n","\n","\n"," \n","# 7. Define model architecture\n","model = Sequential()\n","model.add(Convolution2D(32, 8, 8, activation='relu', input_shape=(128,128,1)))\n","model.add(Convolution2D(64, 4, 4, activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Convolution2D(64, 3, 3, activation='relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n"," \n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(2, activation='softmax'))\n"," \n","model.summary()\n","# 8. Compile model\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n"," \n","# 9. Fit model on training data\n","val=model.fit(X_train, Y_train, \n","          batch_size=64, epochs=300, verbose=1)\n","\n"," \n","# 10. Evaluate model on test data\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print(score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (8, 8), activation=\"relu\", input_shape=(128, 128,...)`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 121, 121, 32)      2080      \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 118, 118, 64)      32832     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 59, 59, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 57, 57, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 50176)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               25690624  \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 1026      \n","=================================================================\n","Total params: 25,763,490\n","Trainable params: 25,763,490\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/300\n","2625/2625 [==============================] - 15s 6ms/step - loss: 0.7586 - acc: 0.5630\n","Epoch 2/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.5551 - acc: 0.7314\n","Epoch 3/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.5051 - acc: 0.7611\n","Epoch 4/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4541 - acc: 0.8019\n","Epoch 5/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4098 - acc: 0.8339\n","Epoch 6/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4002 - acc: 0.8328\n","Epoch 7/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3684 - acc: 0.8533\n","Epoch 8/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4083 - acc: 0.8309\n","Epoch 9/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3634 - acc: 0.8575\n","Epoch 10/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3620 - acc: 0.8484\n","Epoch 11/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3546 - acc: 0.8522\n","Epoch 12/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3481 - acc: 0.8636\n","Epoch 13/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3816 - acc: 0.8457\n","Epoch 14/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3950 - acc: 0.8335\n","Epoch 15/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3650 - acc: 0.8495\n","Epoch 16/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3794 - acc: 0.8366\n","Epoch 17/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3525 - acc: 0.8621\n","Epoch 18/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3342 - acc: 0.8674\n","Epoch 19/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3405 - acc: 0.8655\n","Epoch 20/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3313 - acc: 0.8678\n","Epoch 21/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3292 - acc: 0.8625\n","Epoch 22/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3312 - acc: 0.8670\n","Epoch 23/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3357 - acc: 0.8606\n","Epoch 24/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3261 - acc: 0.8644\n","Epoch 25/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3243 - acc: 0.8682\n","Epoch 26/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3236 - acc: 0.8693\n","Epoch 27/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3279 - acc: 0.8629\n","Epoch 28/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3277 - acc: 0.8636\n","Epoch 29/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3719 - acc: 0.8472\n","Epoch 30/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4113 - acc: 0.8278\n","Epoch 31/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3393 - acc: 0.8594\n","Epoch 32/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3325 - acc: 0.8560\n","Epoch 33/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3508 - acc: 0.8530\n","Epoch 34/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3896 - acc: 0.8301\n","Epoch 35/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3492 - acc: 0.8545\n","Epoch 36/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3265 - acc: 0.8655\n","Epoch 37/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3244 - acc: 0.8621\n","Epoch 38/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3137 - acc: 0.8663\n","Epoch 39/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3147 - acc: 0.8720\n","Epoch 40/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3307 - acc: 0.8564\n","Epoch 41/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3202 - acc: 0.8682\n","Epoch 42/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3197 - acc: 0.8686\n","Epoch 43/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3032 - acc: 0.8712\n","Epoch 44/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3023 - acc: 0.8773\n","Epoch 45/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3056 - acc: 0.8705\n","Epoch 46/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3113 - acc: 0.8731\n","Epoch 47/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3231 - acc: 0.8728\n","Epoch 48/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3102 - acc: 0.8731\n","Epoch 49/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3117 - acc: 0.8682\n","Epoch 50/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2968 - acc: 0.8754\n","Epoch 51/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3241 - acc: 0.8686\n","Epoch 52/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3272 - acc: 0.8640\n","Epoch 53/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3213 - acc: 0.8701\n","Epoch 54/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4076 - acc: 0.8480\n","Epoch 55/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3187 - acc: 0.8697\n","Epoch 56/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3145 - acc: 0.8773\n","Epoch 57/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3035 - acc: 0.8808\n","Epoch 58/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3030 - acc: 0.8716\n","Epoch 59/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3013 - acc: 0.8770\n","Epoch 60/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3026 - acc: 0.8728\n","Epoch 61/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3027 - acc: 0.8716\n","Epoch 62/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3077 - acc: 0.8705\n","Epoch 63/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3182 - acc: 0.8655\n","Epoch 64/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2861 - acc: 0.8846\n","Epoch 65/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2903 - acc: 0.8781\n","Epoch 66/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2825 - acc: 0.8800\n","Epoch 67/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2838 - acc: 0.8758\n","Epoch 68/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3415 - acc: 0.8545\n","Epoch 69/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3119 - acc: 0.8712\n","Epoch 70/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3044 - acc: 0.8712\n","Epoch 71/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2958 - acc: 0.8731\n","Epoch 72/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2905 - acc: 0.8808\n","Epoch 73/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3016 - acc: 0.8724\n","Epoch 74/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2866 - acc: 0.8838\n","Epoch 75/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2865 - acc: 0.8815\n","Epoch 76/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3586 - acc: 0.8472\n","Epoch 77/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2897 - acc: 0.8754\n","Epoch 78/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2875 - acc: 0.8773\n","Epoch 79/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2786 - acc: 0.8895\n","Epoch 80/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2766 - acc: 0.8846\n","Epoch 81/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3005 - acc: 0.8777\n","Epoch 82/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2711 - acc: 0.8861\n","Epoch 83/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2784 - acc: 0.8800\n","Epoch 84/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2988 - acc: 0.8758\n","Epoch 85/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2747 - acc: 0.8834\n","Epoch 86/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2713 - acc: 0.8846\n","Epoch 87/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2657 - acc: 0.8922\n","Epoch 88/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2699 - acc: 0.8819\n","Epoch 89/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2791 - acc: 0.8838\n","Epoch 90/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2972 - acc: 0.8796\n","Epoch 91/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2644 - acc: 0.8926\n","Epoch 92/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2576 - acc: 0.8910\n","Epoch 93/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2658 - acc: 0.8933\n","Epoch 94/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2553 - acc: 0.8960\n","Epoch 95/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2792 - acc: 0.8823\n","Epoch 96/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2511 - acc: 0.8994\n","Epoch 97/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2570 - acc: 0.8983\n","Epoch 98/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2690 - acc: 0.8869\n","Epoch 99/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2542 - acc: 0.8952\n","Epoch 100/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2876 - acc: 0.8777\n","Epoch 101/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2554 - acc: 0.8941\n","Epoch 102/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2484 - acc: 0.8979\n","Epoch 103/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2511 - acc: 0.8952\n","Epoch 104/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2402 - acc: 0.9021\n","Epoch 105/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2453 - acc: 0.9025\n","Epoch 106/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2303 - acc: 0.9048\n","Epoch 107/300\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2411 - acc: 0.9074\n","Epoch 108/300\n"," 576/2625 [=====>........................] - ETA: 6s - loss: 0.2301 - acc: 0.9045"],"name":"stdout"}]},{"metadata":{"id":"6_N88wWGGWqF","colab_type":"code","outputId":"4385a42d-77ae-4ace-ed1b-3a1b259dc803","executionInfo":{"status":"ok","timestamp":1542181856536,"user_tz":-300,"elapsed":1708297,"user":{"displayName":"asif aziz","photoUrl":"https://lh4.googleusercontent.com/-bhMjrwpUA3g/AAAAAAAAAAI/AAAAAAAAAVc/lFmV9OMwqzo/s64/photo.jpg","userId":"14665035055551521181"}},"colab":{"base_uri":"https://localhost:8080/","height":7874}},"cell_type":"code","source":["\n","# 3. Import libraries and modules\n","import numpy as np\n","np.random.seed(123)  # for reproducibility\n","import scipy.io\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Convolution2D, MaxPooling2D\n","from keras.utils import np_utils\n","import numpy as np\n","# Dataset Loading\n","\n","a = scipy.io.loadmat('Dataset_for_CNN2')\n","\n","X_train = a['X_train']\n","X_test = a['X_test']\n","y_train = a['y_train'].astype(int)\n","y_test = a['y_test']\n","\n","\n","\n","X_train = X_train.reshape(X_train.shape[0],128, 128,1)\n","X_test = X_test.reshape(X_test.shape[0],128, 128,1)\n","X_train\n","# Preprocess Input Data\n","X_train = X_train.astype('float64')\n","X_test = X_test.astype('float64')\n","X_train /= 255\n","X_test /= 255\n","\n","Y_train = np_utils.to_categorical(y_train, 2).astype(int)\n","Y_test = np_utils.to_categorical(y_test, 2).astype(int)\n","\n","\n"," #Preprocess Class Labels\n","#converting to one hot notation\n","\n","\n"," \n","# 7. Define model architecture\n","model = Sequential()\n","model.add(Convolution2D(32, 8, 8, activation='relu', input_shape=(128,128,1)))\n","model.add(Convolution2D(64, 4, 4, activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Convolution2D(64, 3, 3, activation='relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n"," \n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(2, activation='softmax'))\n"," \n","model.summary()\n","# 8. Compile model\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n"," \n","# 9. Fit model on training data\n","val=model.fit(X_train, Y_train, \n","          batch_size=64, epochs=200, verbose=1)\n","\n"," \n","# 10. Evaluate model on test data\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print(score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (8, 8), activation=\"relu\", input_shape=(128, 128,...)`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_8 (Conv2D)            (None, 121, 121, 32)      2080      \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 118, 118, 64)      32832     \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 59, 59, 64)        0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 57, 57, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 50176)             0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 512)               25690624  \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 2)                 1026      \n","=================================================================\n","Total params: 25,763,490\n","Trainable params: 25,763,490\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/200\n","2625/2625 [==============================] - 10s 4ms/step - loss: 0.7584 - acc: 0.5490\n","Epoch 2/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.5282 - acc: 0.7516\n","Epoch 3/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.5483 - acc: 0.7276\n","Epoch 4/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4898 - acc: 0.7893\n","Epoch 5/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4651 - acc: 0.8053\n","Epoch 6/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3903 - acc: 0.8419\n","Epoch 7/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3734 - acc: 0.8476\n","Epoch 8/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3955 - acc: 0.8324\n","Epoch 9/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3721 - acc: 0.8453\n","Epoch 10/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3729 - acc: 0.8438\n","Epoch 11/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3461 - acc: 0.8610\n","Epoch 12/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3694 - acc: 0.8533\n","Epoch 13/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3885 - acc: 0.8419\n","Epoch 14/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3612 - acc: 0.8583\n","Epoch 15/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3434 - acc: 0.8602\n","Epoch 16/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3419 - acc: 0.8575\n","Epoch 17/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3368 - acc: 0.8571\n","Epoch 18/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3463 - acc: 0.8537\n","Epoch 19/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3671 - acc: 0.8450\n","Epoch 20/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3394 - acc: 0.8644\n","Epoch 21/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3258 - acc: 0.8690\n","Epoch 22/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3336 - acc: 0.8556\n","Epoch 23/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3443 - acc: 0.8568\n","Epoch 24/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3295 - acc: 0.8629\n","Epoch 25/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3385 - acc: 0.8590\n","Epoch 26/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3338 - acc: 0.8636\n","Epoch 27/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3306 - acc: 0.8590\n","Epoch 28/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3303 - acc: 0.8629\n","Epoch 29/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3662 - acc: 0.8457\n","Epoch 30/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3760 - acc: 0.8404\n","Epoch 31/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3521 - acc: 0.8503\n","Epoch 32/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3265 - acc: 0.8655\n","Epoch 33/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3463 - acc: 0.8526\n","Epoch 34/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.4192 - acc: 0.8286\n","Epoch 35/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3727 - acc: 0.8484\n","Epoch 36/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3361 - acc: 0.8594\n","Epoch 37/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3234 - acc: 0.8690\n","Epoch 38/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3144 - acc: 0.8690\n","Epoch 39/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3115 - acc: 0.8758\n","Epoch 40/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3155 - acc: 0.8670\n","Epoch 41/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3293 - acc: 0.8686\n","Epoch 42/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3094 - acc: 0.8724\n","Epoch 43/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3100 - acc: 0.8747\n","Epoch 44/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3113 - acc: 0.8754\n","Epoch 45/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3055 - acc: 0.8792\n","Epoch 46/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3126 - acc: 0.8682\n","Epoch 47/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3128 - acc: 0.8743\n","Epoch 48/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2990 - acc: 0.8762\n","Epoch 49/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2991 - acc: 0.8701\n","Epoch 50/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2968 - acc: 0.8811\n","Epoch 51/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3197 - acc: 0.8754\n","Epoch 52/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3222 - acc: 0.8583\n","Epoch 53/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3060 - acc: 0.8754\n","Epoch 54/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3011 - acc: 0.8728\n","Epoch 55/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3355 - acc: 0.8606\n","Epoch 56/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3220 - acc: 0.8682\n","Epoch 57/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3237 - acc: 0.8739\n","Epoch 58/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3141 - acc: 0.8598\n","Epoch 59/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2988 - acc: 0.8731\n","Epoch 60/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2952 - acc: 0.8770\n","Epoch 61/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2976 - acc: 0.8735\n","Epoch 62/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3027 - acc: 0.8724\n","Epoch 63/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4181 - acc: 0.8251\n","Epoch 64/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3265 - acc: 0.8663\n","Epoch 65/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3126 - acc: 0.8670\n","Epoch 66/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2936 - acc: 0.8724\n","Epoch 67/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2954 - acc: 0.8830\n","Epoch 68/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4077 - acc: 0.8270\n","Epoch 69/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3492 - acc: 0.8495\n","Epoch 70/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3127 - acc: 0.8667\n","Epoch 71/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2984 - acc: 0.8766\n","Epoch 72/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2990 - acc: 0.8743\n","Epoch 73/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2925 - acc: 0.8770\n","Epoch 74/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2963 - acc: 0.8720\n","Epoch 75/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2923 - acc: 0.8789\n","Epoch 76/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3390 - acc: 0.8617\n","Epoch 77/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2917 - acc: 0.8750\n","Epoch 78/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2882 - acc: 0.8823\n","Epoch 79/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2759 - acc: 0.8815\n","Epoch 80/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2753 - acc: 0.8872\n","Epoch 81/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2881 - acc: 0.8728\n","Epoch 82/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2720 - acc: 0.8846\n","Epoch 83/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2764 - acc: 0.8827\n","Epoch 84/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2831 - acc: 0.8789\n","Epoch 85/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2701 - acc: 0.8869\n","Epoch 86/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2672 - acc: 0.8865\n","Epoch 87/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2711 - acc: 0.8907\n","Epoch 88/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2599 - acc: 0.8914\n","Epoch 89/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2608 - acc: 0.8895\n","Epoch 90/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2914 - acc: 0.8762\n","Epoch 91/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2509 - acc: 0.8956\n","Epoch 92/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2460 - acc: 0.8956\n","Epoch 93/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2431 - acc: 0.9032\n","Epoch 94/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2387 - acc: 0.9032\n","Epoch 95/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2415 - acc: 0.8987\n","Epoch 96/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2198 - acc: 0.9105\n","Epoch 97/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2108 - acc: 0.9131\n","Epoch 98/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2043 - acc: 0.9166\n","Epoch 99/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2230 - acc: 0.9025\n","Epoch 100/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3048 - acc: 0.8701\n","Epoch 101/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2375 - acc: 0.9032\n","Epoch 102/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2083 - acc: 0.9154\n","Epoch 103/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2163 - acc: 0.9086\n","Epoch 104/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2071 - acc: 0.9135\n","Epoch 105/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1836 - acc: 0.9242\n","Epoch 106/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1727 - acc: 0.9291\n","Epoch 107/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1896 - acc: 0.9284\n","Epoch 108/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1651 - acc: 0.9303\n","Epoch 109/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1620 - acc: 0.9356\n","Epoch 110/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1452 - acc: 0.9410\n","Epoch 111/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1269 - acc: 0.9512\n","Epoch 112/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1276 - acc: 0.9543\n","Epoch 113/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2677 - acc: 0.8853\n","Epoch 114/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1537 - acc: 0.9387\n","Epoch 115/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1394 - acc: 0.9410\n","Epoch 116/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1312 - acc: 0.9432\n","Epoch 117/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1148 - acc: 0.9547\n","Epoch 118/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1125 - acc: 0.9528\n","Epoch 119/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1233 - acc: 0.9516\n","Epoch 120/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1064 - acc: 0.9619\n","Epoch 121/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0952 - acc: 0.9619\n","Epoch 122/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0844 - acc: 0.9703\n","Epoch 123/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0954 - acc: 0.9653\n","Epoch 124/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0774 - acc: 0.9699\n","Epoch 125/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0815 - acc: 0.9699\n","Epoch 126/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0872 - acc: 0.9627\n","Epoch 127/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1050 - acc: 0.9577\n","Epoch 128/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0785 - acc: 0.9722\n","Epoch 129/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0679 - acc: 0.9745\n","Epoch 130/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0580 - acc: 0.9787\n","Epoch 131/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0534 - acc: 0.9836\n","Epoch 132/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0491 - acc: 0.9813\n","Epoch 133/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0848 - acc: 0.9691\n","Epoch 134/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1034 - acc: 0.9596\n","Epoch 135/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0592 - acc: 0.9790\n","Epoch 136/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0499 - acc: 0.9825\n","Epoch 137/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0459 - acc: 0.9867\n","Epoch 138/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0813 - acc: 0.9691\n","Epoch 139/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0448 - acc: 0.9859\n","Epoch 140/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0346 - acc: 0.9905\n","Epoch 141/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0439 - acc: 0.9844\n","Epoch 142/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0458 - acc: 0.9825\n","Epoch 143/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0368 - acc: 0.9901\n","Epoch 144/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0326 - acc: 0.9901\n","Epoch 145/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0254 - acc: 0.9912\n","Epoch 146/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0302 - acc: 0.9893\n","Epoch 147/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0382 - acc: 0.9855\n","Epoch 148/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0420 - acc: 0.9836\n","Epoch 149/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0298 - acc: 0.9909\n","Epoch 150/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0319 - acc: 0.9905\n","Epoch 151/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0266 - acc: 0.9916\n","Epoch 152/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0221 - acc: 0.9939\n","Epoch 153/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0175 - acc: 0.9947\n","Epoch 154/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0237 - acc: 0.9931\n","Epoch 155/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0263 - acc: 0.9912\n","Epoch 156/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0213 - acc: 0.9924\n","Epoch 157/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0230 - acc: 0.9931\n","Epoch 158/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0181 - acc: 0.9943\n","Epoch 159/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0228 - acc: 0.9924\n","Epoch 160/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0237 - acc: 0.9943\n","Epoch 161/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0173 - acc: 0.9931\n","Epoch 162/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0145 - acc: 0.9962\n","Epoch 163/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0095 - acc: 0.9985\n","Epoch 164/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0122 - acc: 0.9962\n","Epoch 165/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0098 - acc: 0.9970\n","Epoch 166/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0138 - acc: 0.9958\n","Epoch 167/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0065 - acc: 0.9985\n","Epoch 168/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0088 - acc: 0.9970\n","Epoch 169/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0190 - acc: 0.9935\n","Epoch 170/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0151 - acc: 0.9947\n","Epoch 171/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0070 - acc: 0.9985\n","Epoch 172/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0204 - acc: 0.9924\n","Epoch 173/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0203 - acc: 0.9947\n","Epoch 174/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0155 - acc: 0.9947\n","Epoch 175/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0331 - acc: 0.9878\n","Epoch 176/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0126 - acc: 0.9958\n","Epoch 177/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0108 - acc: 0.9970\n","Epoch 178/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0148 - acc: 0.9958\n","Epoch 179/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0205 - acc: 0.9931\n","Epoch 180/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0163 - acc: 0.9954\n","Epoch 181/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0096 - acc: 0.9977\n","Epoch 182/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0174 - acc: 0.9935\n","Epoch 183/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0068 - acc: 0.9985\n","Epoch 184/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0067 - acc: 0.9973\n","Epoch 185/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0124 - acc: 0.9970\n","Epoch 186/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0175 - acc: 0.9939\n","Epoch 187/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0372 - acc: 0.9870\n","Epoch 188/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0482 - acc: 0.9813\n","Epoch 189/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0125 - acc: 0.9966\n","Epoch 190/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0062 - acc: 0.9989\n","Epoch 191/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0052 - acc: 0.9992\n","Epoch 192/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0054 - acc: 0.9985\n","Epoch 193/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0187 - acc: 0.9920\n","Epoch 194/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0090 - acc: 0.9981\n","Epoch 195/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0217 - acc: 0.9924\n","Epoch 196/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0076 - acc: 0.9981\n","Epoch 197/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0090 - acc: 0.9996\n","Epoch 198/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0034 - acc: 0.9992\n","Epoch 199/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0035 - acc: 0.9996\n","Epoch 200/200\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0023 - acc: 0.9996\n","[0.5117940265094663, 0.9103019538188277]\n"],"name":"stdout"}]},{"metadata":{"id":"EKcLxK-y7IrT","colab_type":"code","outputId":"2b980eda-3ed4-4830-f7d9-c88129f00d60","executionInfo":{"status":"ok","timestamp":1542178778763,"user_tz":-300,"elapsed":1534416,"user":{"displayName":"asif aziz","photoUrl":"https://lh4.googleusercontent.com/-bhMjrwpUA3g/AAAAAAAAAAI/AAAAAAAAAVc/lFmV9OMwqzo/s64/photo.jpg","userId":"14665035055551521181"}},"colab":{"base_uri":"https://localhost:8080/","height":8001}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon Nov 12 15:17:45 2018\n","\n","@author: Asif\n","\"\"\"\n","\n","# 3. Import libraries and modules\n","import numpy as np\n","np.random.seed(123)  # for reproducibility\n","import scipy.io\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Convolution2D, MaxPooling2D\n","from keras.utils import np_utils\n","import numpy as np\n","# Dataset Loading\n","\n","a = scipy.io.loadmat('Dataset_for_CNN2')\n","\n","X_train = a['X_train']\n","X_test = a['X_test']\n","y_train = a['y_train'].astype(int)\n","y_test = a['y_test']\n","\n","\n","\n","X_train = X_train.reshape(X_train.shape[0],128, 128,1)\n","X_test = X_test.reshape(X_test.shape[0],128, 128,1)\n","X_train\n","# Preprocess Input Data\n","X_train = X_train.astype('float64')\n","X_test = X_test.astype('float64')\n","X_train /= 255\n","X_test /= 255\n","\n","Y_train = np_utils.to_categorical(y_train, 2).astype(int)\n","Y_test = np_utils.to_categorical(y_test, 2).astype(int)\n","\n","\n"," #Preprocess Class Labels\n","#converting to one hot notation\n","\n","\n"," \n","# 7. Define model architecture\n","model = Sequential()\n","model.add(Convolution2D(32, 8, 8, activation='relu', input_shape=(128,128,1)))\n","model.add(Convolution2D(64, 4, 4, activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Convolution2D(64, 3, 3, activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","model.add(Convolution2D(64, 3, 3, activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2))) \n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(2, activation='softmax'))\n"," \n","model.summary()\n","# 8. Compile model\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n"," \n","# 9. Fit model on training data\n","val=model.fit(X_train, Y_train, \n","          batch_size=64, epochs=200, verbose=1)\n","\n"," \n","# 10. Evaluate model on test data\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print(score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (8, 8), activation=\"relu\", input_shape=(128, 128,...)`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 121, 121, 32)      2080      \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 118, 118, 64)      32832     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 59, 59, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 57, 57, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 26, 26, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 10816)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               5538304   \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 1026      \n","=================================================================\n","Total params: 5,648,098\n","Trainable params: 5,648,098\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/200\n","2625/2625 [==============================] - 13s 5ms/step - loss: 0.6496 - acc: 0.6171\n","Epoch 2/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.5179 - acc: 0.7703\n","Epoch 3/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.4655 - acc: 0.8011\n","Epoch 4/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.4134 - acc: 0.8297\n","Epoch 5/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3980 - acc: 0.8301\n","Epoch 6/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.4831 - acc: 0.7901\n","Epoch 7/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.4107 - acc: 0.8290\n","Epoch 8/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3918 - acc: 0.8389\n","Epoch 9/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3759 - acc: 0.8465\n","Epoch 10/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3645 - acc: 0.8484\n","Epoch 11/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3965 - acc: 0.8331\n","Epoch 12/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3563 - acc: 0.8552\n","Epoch 13/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3716 - acc: 0.8415\n","Epoch 14/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3585 - acc: 0.8480\n","Epoch 15/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3520 - acc: 0.8564\n","Epoch 16/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3460 - acc: 0.8522\n","Epoch 17/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3562 - acc: 0.8518\n","Epoch 18/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3661 - acc: 0.8484\n","Epoch 19/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3507 - acc: 0.8571\n","Epoch 20/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3537 - acc: 0.8469\n","Epoch 21/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3415 - acc: 0.8552\n","Epoch 22/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3435 - acc: 0.8530\n","Epoch 23/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3784 - acc: 0.8537\n","Epoch 24/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3342 - acc: 0.8617\n","Epoch 25/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3353 - acc: 0.8602\n","Epoch 26/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3681 - acc: 0.8522\n","Epoch 27/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3509 - acc: 0.8598\n","Epoch 28/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3370 - acc: 0.8617\n","Epoch 29/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3377 - acc: 0.8590\n","Epoch 30/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3311 - acc: 0.8579\n","Epoch 31/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3606 - acc: 0.8469\n","Epoch 32/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3258 - acc: 0.8724\n","Epoch 33/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3412 - acc: 0.8564\n","Epoch 34/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3174 - acc: 0.8716\n","Epoch 35/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3205 - acc: 0.8632\n","Epoch 36/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3256 - acc: 0.8648\n","Epoch 37/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3988 - acc: 0.8309\n","Epoch 38/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3418 - acc: 0.8575\n","Epoch 39/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3364 - acc: 0.8602\n","Epoch 40/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3247 - acc: 0.8651\n","Epoch 41/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.4504 - acc: 0.8206\n","Epoch 42/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3541 - acc: 0.8526\n","Epoch 43/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3261 - acc: 0.8705\n","Epoch 44/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3169 - acc: 0.8663\n","Epoch 45/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3263 - acc: 0.8667\n","Epoch 46/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3229 - acc: 0.8743\n","Epoch 47/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3467 - acc: 0.8579\n","Epoch 48/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3330 - acc: 0.8625\n","Epoch 49/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3216 - acc: 0.8728\n","Epoch 50/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3155 - acc: 0.8663\n","Epoch 51/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3313 - acc: 0.8651\n","Epoch 52/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3106 - acc: 0.8697\n","Epoch 53/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3839 - acc: 0.8404\n","Epoch 54/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3276 - acc: 0.8644\n","Epoch 55/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3367 - acc: 0.8590\n","Epoch 56/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3111 - acc: 0.8720\n","Epoch 57/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3130 - acc: 0.8606\n","Epoch 58/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3077 - acc: 0.8731\n","Epoch 59/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3097 - acc: 0.8716\n","Epoch 60/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3040 - acc: 0.8762\n","Epoch 61/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3243 - acc: 0.8659\n","Epoch 62/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3067 - acc: 0.8728\n","Epoch 63/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.4370 - acc: 0.8190\n","Epoch 64/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3493 - acc: 0.8579\n","Epoch 65/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3255 - acc: 0.8640\n","Epoch 66/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3135 - acc: 0.8678\n","Epoch 67/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3144 - acc: 0.8709\n","Epoch 68/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3188 - acc: 0.8640\n","Epoch 69/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3092 - acc: 0.8735\n","Epoch 70/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3216 - acc: 0.8667\n","Epoch 71/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3019 - acc: 0.8773\n","Epoch 72/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2965 - acc: 0.8773\n","Epoch 73/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3247 - acc: 0.8636\n","Epoch 74/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3379 - acc: 0.8537\n","Epoch 75/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3205 - acc: 0.8659\n","Epoch 76/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3217 - acc: 0.8648\n","Epoch 77/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3203 - acc: 0.8640\n","Epoch 78/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3685 - acc: 0.8465\n","Epoch 79/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3495 - acc: 0.8533\n","Epoch 80/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3357 - acc: 0.8621\n","Epoch 81/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3246 - acc: 0.8678\n","Epoch 82/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3066 - acc: 0.8766\n","Epoch 83/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2988 - acc: 0.8792\n","Epoch 84/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2882 - acc: 0.8865\n","Epoch 85/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2939 - acc: 0.8785\n","Epoch 86/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2912 - acc: 0.8762\n","Epoch 87/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3037 - acc: 0.8808\n","Epoch 88/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2915 - acc: 0.8823\n","Epoch 89/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.4161 - acc: 0.8244\n","Epoch 90/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3697 - acc: 0.8507\n","Epoch 91/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3667 - acc: 0.8541\n","Epoch 92/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3039 - acc: 0.8796\n","Epoch 93/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2930 - acc: 0.8842\n","Epoch 94/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2807 - acc: 0.8899\n","Epoch 95/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2902 - acc: 0.8796\n","Epoch 96/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2698 - acc: 0.8872\n","Epoch 97/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2934 - acc: 0.8735\n","Epoch 98/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2792 - acc: 0.8865\n","Epoch 99/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2722 - acc: 0.8880\n","Epoch 100/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2710 - acc: 0.8903\n","Epoch 101/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2585 - acc: 0.8876\n","Epoch 102/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2517 - acc: 0.8979\n","Epoch 103/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2577 - acc: 0.8910\n","Epoch 104/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2454 - acc: 0.9006\n","Epoch 105/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2570 - acc: 0.9002\n","Epoch 106/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2360 - acc: 0.9010\n","Epoch 107/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2335 - acc: 0.9021\n","Epoch 108/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2522 - acc: 0.8956\n","Epoch 109/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2326 - acc: 0.9017\n","Epoch 110/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2220 - acc: 0.9059\n","Epoch 111/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2509 - acc: 0.8994\n","Epoch 112/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2265 - acc: 0.9029\n","Epoch 113/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2141 - acc: 0.9112\n","Epoch 114/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2154 - acc: 0.9097\n","Epoch 115/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2111 - acc: 0.9109\n","Epoch 116/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2068 - acc: 0.9158\n","Epoch 117/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2256 - acc: 0.9093\n","Epoch 118/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2014 - acc: 0.9147\n","Epoch 119/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2201 - acc: 0.9078\n","Epoch 120/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2090 - acc: 0.9135\n","Epoch 121/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2406 - acc: 0.8964\n","Epoch 122/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2124 - acc: 0.9078\n","Epoch 123/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2006 - acc: 0.9181\n","Epoch 124/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2048 - acc: 0.9150\n","Epoch 125/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2776 - acc: 0.8838\n","Epoch 126/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3360 - acc: 0.8625\n","Epoch 127/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2389 - acc: 0.8987\n","Epoch 128/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2020 - acc: 0.9185\n","Epoch 129/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1905 - acc: 0.9246\n","Epoch 130/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1838 - acc: 0.9261\n","Epoch 131/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1802 - acc: 0.9253\n","Epoch 132/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3044 - acc: 0.8770\n","Epoch 133/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2016 - acc: 0.9192\n","Epoch 134/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2018 - acc: 0.9147\n","Epoch 135/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1760 - acc: 0.9261\n","Epoch 136/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.4399 - acc: 0.8202\n","Epoch 137/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.3432 - acc: 0.8560\n","Epoch 138/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2386 - acc: 0.9021\n","Epoch 139/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1982 - acc: 0.9131\n","Epoch 140/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1874 - acc: 0.9227\n","Epoch 141/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1834 - acc: 0.9208\n","Epoch 142/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2206 - acc: 0.9040\n","Epoch 143/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1731 - acc: 0.9265\n","Epoch 144/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1663 - acc: 0.9333\n","Epoch 145/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1640 - acc: 0.9352\n","Epoch 146/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1920 - acc: 0.9227\n","Epoch 147/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1709 - acc: 0.9310\n","Epoch 148/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1605 - acc: 0.9371\n","Epoch 149/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1360 - acc: 0.9459\n","Epoch 150/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1367 - acc: 0.9467\n","Epoch 151/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1613 - acc: 0.9352\n","Epoch 152/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1539 - acc: 0.9364\n","Epoch 153/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1481 - acc: 0.9406\n","Epoch 154/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1317 - acc: 0.9467\n","Epoch 155/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1214 - acc: 0.9520\n","Epoch 156/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1229 - acc: 0.9463\n","Epoch 157/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1200 - acc: 0.9509\n","Epoch 158/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1188 - acc: 0.9520\n","Epoch 159/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1198 - acc: 0.9543\n","Epoch 160/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1254 - acc: 0.9501\n","Epoch 161/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1142 - acc: 0.9543\n","Epoch 162/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1102 - acc: 0.9566\n","Epoch 163/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1557 - acc: 0.9417\n","Epoch 164/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1080 - acc: 0.9589\n","Epoch 165/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0952 - acc: 0.9661\n","Epoch 166/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1293 - acc: 0.9455\n","Epoch 167/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1046 - acc: 0.9596\n","Epoch 168/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0926 - acc: 0.9630\n","Epoch 169/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0881 - acc: 0.9650\n","Epoch 170/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0934 - acc: 0.9634\n","Epoch 171/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0801 - acc: 0.9688\n","Epoch 172/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0883 - acc: 0.9642\n","Epoch 173/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0934 - acc: 0.9657\n","Epoch 174/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0851 - acc: 0.9630\n","Epoch 175/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0913 - acc: 0.9619\n","Epoch 176/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0746 - acc: 0.9680\n","Epoch 177/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0750 - acc: 0.9718\n","Epoch 178/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0760 - acc: 0.9669\n","Epoch 179/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0839 - acc: 0.9684\n","Epoch 180/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0813 - acc: 0.9665\n","Epoch 181/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0658 - acc: 0.9752\n","Epoch 182/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0660 - acc: 0.9722\n","Epoch 183/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0702 - acc: 0.9752\n","Epoch 184/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0572 - acc: 0.9790\n","Epoch 185/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0625 - acc: 0.9756\n","Epoch 186/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0641 - acc: 0.9756\n","Epoch 187/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0577 - acc: 0.9790\n","Epoch 188/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0598 - acc: 0.9764\n","Epoch 189/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0930 - acc: 0.9676\n","Epoch 190/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0648 - acc: 0.9756\n","Epoch 191/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0578 - acc: 0.9771\n","Epoch 192/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0576 - acc: 0.9813\n","Epoch 193/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0613 - acc: 0.9768\n","Epoch 194/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0585 - acc: 0.9798\n","Epoch 195/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1477 - acc: 0.9448\n","Epoch 196/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0717 - acc: 0.9703\n","Epoch 197/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.2340 - acc: 0.9227\n","Epoch 198/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.1120 - acc: 0.9615\n","Epoch 199/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0745 - acc: 0.9760\n","Epoch 200/200\n","2625/2625 [==============================] - 8s 3ms/step - loss: 0.0776 - acc: 0.9730\n","[0.31002061376943657, 0.9147424511545293]\n"],"name":"stdout"}]},{"metadata":{"id":"retosSwLt7IK","colab_type":"code","outputId":"402655fd-d432-4ed7-f5f7-a20aaf42dab6","executionInfo":{"status":"error","timestamp":1542174936180,"user_tz":-300,"elapsed":1792,"user":{"displayName":"asif aziz","photoUrl":"https://lh4.googleusercontent.com/-bhMjrwpUA3g/AAAAAAAAAAI/AAAAAAAAAVc/lFmV9OMwqzo/s64/photo.jpg","userId":"14665035055551521181"}},"colab":{"base_uri":"https://localhost:8080/","height":482}},"cell_type":"code","source":["import numpy as np\n","np.random.seed(123)  # for reproducibility\n","import scipy.io\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Convolution2D, MaxPooling2D\n","from keras.utils import np_utils\n","import numpy as np\n","# Dataset Loading\n","\n","a = scipy.io.loadmat('Dataset_for_CNN2')\n","\n","X_train = a['X_train']\n","X_test = a['X_test']\n","y_train = a['y_train'].astype(int)\n","y_test = a['y_test']\n","\n","\n","\n","X_train = X_train.reshape(X_train.shape[0],128, 128,1)\n","X_test = X_test.reshape(X_test.shape[0],128, 128,1)\n","X_train\n","# Preprocess Input Data\n","X_train = X_train.astype('float64')\n","X_test = X_test.astype('float64')\n","X_train /= 255\n","X_test /= 255\n","\n","Y_train = np_utils.to_categorical(y_train, 2).astype(int)\n","Y_test = np_utils.to_categorical(y_test, 2).astype(int)\n","\n","import matplotlib.pyplot as plt\n","plt.show(X_train[1])\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-b69f82b2287c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# only call close('all') if any to close\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# close triggers gc.collect, which can be slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"]}]},{"metadata":{"id":"BmRw8dfkQrna","colab_type":"code","outputId":"b970a66e-b284-4934-9370-c0a9a4c26625","executionInfo":{"status":"ok","timestamp":1542132573426,"user_tz":-300,"elapsed":2775,"user":{"displayName":"asif aziz","photoUrl":"https://lh4.googleusercontent.com/-bhMjrwpUA3g/AAAAAAAAAAI/AAAAAAAAAVc/lFmV9OMwqzo/s64/photo.jpg","userId":"14665035055551521181"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print(score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0.4919667464318199, 0.8969804618117229]\n"],"name":"stdout"}]},{"metadata":{"id":"kF7O3JaXqr1j","colab_type":"code","outputId":"8710796b-de8a-422a-dfe4-61a181167ef2","executionInfo":{"status":"ok","timestamp":1542122587699,"user_tz":-300,"elapsed":2709,"user":{"displayName":"asif aziz","photoUrl":"https://lh4.googleusercontent.com/-bhMjrwpUA3g/AAAAAAAAAAI/AAAAAAAAAVc/lFmV9OMwqzo/s64/photo.jpg","userId":"14665035055551521181"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# 10. Evaluate model on test data\n","model.evaluate(X_test, Y_test, verbose=0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.36280813307588633, 0.9200710479573713]"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"WgrsEC1PnHOq","colab_type":"code","colab":{}},"cell_type":"code","source":["model.fit(X_train, Y_train, \n","          batch_size=64, epochs=100, verbose=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-HV3NZemnIvb","colab_type":"code","outputId":"ee4a0f4b-5d3f-4e1f-e94d-a58bbaebcd0a","executionInfo":{"status":"ok","timestamp":1542122540225,"user_tz":-300,"elapsed":889943,"user":{"displayName":"asif aziz","photoUrl":"https://lh4.googleusercontent.com/-bhMjrwpUA3g/AAAAAAAAAAI/AAAAAAAAAVc/lFmV9OMwqzo/s64/photo.jpg","userId":"14665035055551521181"}},"colab":{"base_uri":"https://localhost:8080/","height":3672}},"cell_type":"code","source":["model.fit(X_train, Y_train, \n","          batch_size=64, epochs=100, verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2746 - acc: 0.8872\n","Epoch 2/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2487 - acc: 0.8979\n","Epoch 3/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2357 - acc: 0.9006\n","Epoch 4/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2458 - acc: 0.8971\n","Epoch 5/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2242 - acc: 0.9036\n","Epoch 6/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2144 - acc: 0.9120\n","Epoch 7/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2084 - acc: 0.9109\n","Epoch 8/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2122 - acc: 0.9139\n","Epoch 9/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2020 - acc: 0.9181\n","Epoch 10/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2285 - acc: 0.9105\n","Epoch 11/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1903 - acc: 0.9223\n","Epoch 12/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1942 - acc: 0.9250\n","Epoch 13/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2033 - acc: 0.9147\n","Epoch 14/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1883 - acc: 0.9185\n","Epoch 15/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1806 - acc: 0.9272\n","Epoch 16/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1759 - acc: 0.9219\n","Epoch 17/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4470 - acc: 0.8213\n","Epoch 18/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2385 - acc: 0.9025\n","Epoch 19/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1984 - acc: 0.9234\n","Epoch 20/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4275 - acc: 0.8358\n","Epoch 21/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3929 - acc: 0.8343\n","Epoch 22/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3694 - acc: 0.8491\n","Epoch 23/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2163 - acc: 0.9135\n","Epoch 24/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1931 - acc: 0.9189\n","Epoch 25/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1771 - acc: 0.9310\n","Epoch 26/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1676 - acc: 0.9375\n","Epoch 27/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1575 - acc: 0.9429\n","Epoch 28/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1414 - acc: 0.9417\n","Epoch 29/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1829 - acc: 0.9250\n","Epoch 30/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1469 - acc: 0.9444\n","Epoch 31/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1328 - acc: 0.9470\n","Epoch 32/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1378 - acc: 0.9421\n","Epoch 33/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1356 - acc: 0.9451\n","Epoch 34/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1227 - acc: 0.9520\n","Epoch 35/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1300 - acc: 0.9505\n","Epoch 36/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1128 - acc: 0.9543\n","Epoch 37/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1287 - acc: 0.9486\n","Epoch 38/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1173 - acc: 0.9524\n","Epoch 39/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1096 - acc: 0.9550\n","Epoch 40/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1019 - acc: 0.9611\n","Epoch 41/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0993 - acc: 0.9615\n","Epoch 42/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.4039 - acc: 0.8461\n","Epoch 43/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.5319 - acc: 0.7825\n","Epoch 44/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3108 - acc: 0.8739\n","Epoch 45/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.2198 - acc: 0.9116\n","Epoch 46/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1487 - acc: 0.9493\n","Epoch 47/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1394 - acc: 0.9463\n","Epoch 48/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.3392 - acc: 0.8514\n","Epoch 49/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1914 - acc: 0.9269\n","Epoch 50/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1349 - acc: 0.9478\n","Epoch 51/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1151 - acc: 0.9577\n","Epoch 52/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1036 - acc: 0.9611\n","Epoch 53/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1236 - acc: 0.9505\n","Epoch 54/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0955 - acc: 0.9688\n","Epoch 55/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0908 - acc: 0.9669\n","Epoch 56/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0855 - acc: 0.9699\n","Epoch 57/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0898 - acc: 0.9653\n","Epoch 58/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0744 - acc: 0.9722\n","Epoch 59/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.1014 - acc: 0.9604\n","Epoch 60/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0839 - acc: 0.9718\n","Epoch 61/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0746 - acc: 0.9737\n","Epoch 62/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0640 - acc: 0.9768\n","Epoch 63/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0607 - acc: 0.9794\n","Epoch 64/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0563 - acc: 0.9787\n","Epoch 65/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0617 - acc: 0.9802\n","Epoch 66/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0585 - acc: 0.9787\n","Epoch 67/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0543 - acc: 0.9832\n","Epoch 68/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0524 - acc: 0.9817\n","Epoch 69/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0461 - acc: 0.9848\n","Epoch 70/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0681 - acc: 0.9745\n","Epoch 71/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0544 - acc: 0.9825\n","Epoch 72/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0526 - acc: 0.9829\n","Epoch 73/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0492 - acc: 0.9829\n","Epoch 74/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0451 - acc: 0.9844\n","Epoch 75/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0401 - acc: 0.9851\n","Epoch 76/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0348 - acc: 0.9890\n","Epoch 77/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0307 - acc: 0.9912\n","Epoch 78/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0360 - acc: 0.9870\n","Epoch 79/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0309 - acc: 0.9893\n","Epoch 80/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0334 - acc: 0.9882\n","Epoch 81/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0270 - acc: 0.9920\n","Epoch 82/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0277 - acc: 0.9912\n","Epoch 83/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0356 - acc: 0.9882\n","Epoch 84/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0291 - acc: 0.9909\n","Epoch 85/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0276 - acc: 0.9909\n","Epoch 86/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0446 - acc: 0.9874\n","Epoch 87/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0262 - acc: 0.9912\n","Epoch 88/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0325 - acc: 0.9905\n","Epoch 89/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0260 - acc: 0.9924\n","Epoch 90/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0266 - acc: 0.9912\n","Epoch 91/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0205 - acc: 0.9928\n","Epoch 92/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0225 - acc: 0.9947\n","Epoch 93/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0240 - acc: 0.9928\n","Epoch 94/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0227 - acc: 0.9943\n","Epoch 95/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0192 - acc: 0.9939\n","Epoch 96/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0178 - acc: 0.9962\n","Epoch 97/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0191 - acc: 0.9928\n","Epoch 98/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0499 - acc: 0.9829\n","Epoch 99/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0311 - acc: 0.9886\n","Epoch 100/100\n","2625/2625 [==============================] - 9s 3ms/step - loss: 0.0179 - acc: 0.9947\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f543b7c6b70>"]},"metadata":{"tags":[]},"execution_count":7}]}]}